<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Golang | Duck</title><meta name=keywords content><meta name=description content="ExampleSite description"><meta name=author content><link rel=canonical href=https://duck-dd.github.io/tags/golang/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.2a8ef18cccda149eb1cd8ec968ba463447d72022979e5c5cae43dcf5d7358750.css integrity="sha256-Ko7xjMzaFJ6xzY7JaLpGNEfXICKXnlxcrkPc9dc1h1A=" rel="preload stylesheet" as=style><link rel=icon href=https://duck-dd.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://duck-dd.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://duck-dd.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://duck-dd.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://duck-dd.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://duck-dd.github.io/tags/golang/index.xml><link rel=alternate hreflang=en href=https://duck-dd.github.io/tags/golang/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><meta property="og:url" content="https://duck-dd.github.io/tags/golang/"><meta property="og:site_name" content="Duck"><meta property="og:title" content="Golang"><meta property="og:description" content="ExampleSite description"><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta property="og:image" content="https://duck-dd.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://duck-dd.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Golang"><meta name=twitter:description content="ExampleSite description"></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://duck-dd.github.io/ accesskey=h title="首页 (Alt + H)"><img src=https://duck-dd.github.io/apple-touch-icon.png alt aria-label=logo height=35>首页</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://duck-dd.github.io/categories/ title=分类><span>分类</span></a></li><li><a href=https://duck-dd.github.io/tags/ title=标签><span>标签</span></a></li><li><a href=https://duck-dd.github.io/about_me title=关于我><span>关于我</span></a></li><li><a href=https://duck-dd.github.io/about_space title=关于这里><span>关于这里</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://duck-dd.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://duck-dd.github.io/tags/>Tags</a></div><h1>Golang
<a href=/tags/golang/index.xml title=RSS aria-label=RSS><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>go tips(持续更新)</h2></header><div class=entry-content><p>有很多从其他大佬的总结中抄来的，不注明出处了
会记录一些:
有意义的小操作(可能有些比较tricky) 容易理解偏差的点 日常开发低频使用的知识点 golang代码执行顺序 没有并发，一个顺序逻辑，CPU真正执行指令不一定与编码顺序完全一致，Go的编译器会做优化，前提是会解决依赖逻辑，看起来是“顺序执行”这一假设。
了解更多可查看Golang内存模型规范。
golang内存对齐 内存对齐：数据在内存中的存储位置必须是特定字节数的倍数
CPU访问内存时，通常按固定大小的块（如4字节或8字节）读取，不对齐的数据可能导致需要两次访问 golang内存对齐：
基础类型：通常是其自身大小（如int32为4字节，int64为8字节） 结构体 每个字段按各自的对齐系数作对齐 结构体自身的对齐系数为所有字段中最大的对齐系数 数组：与元素类型的对齐系数相同 例：
type demo1 struct { a int8 b int16 c int32 } type demo2 struct { a int8 c int32 b int16 } type demo3 struct { a int8 c int32 b int16 d int16 } func main() { fmt.Println(unsafe.Sizeof(demo1{})) // 8 fmt.Println(unsafe.Sizeof(demo2{})) // 12 fmt.Println(unsafe.Sizeof(demo3{})) // 12 } demo1:
a 是第一个字段，默认是已经对齐的，从第 0 个位置开始占据 1 字节 b 是第二个字段，对齐倍数为 2，因此，必须空出 1 个字节，偏移量才是 2 的倍数，从第 2 个位置开始占据 2 字节 c 是第三个字段，对齐倍数为 4，此时，内存已经是对齐的，从第 4 个位置开始占据 4 字节即可 demo2:
...</p></div><footer class=entry-footer><span title='2025-06-22 00:00:00 +0000 UTC'>2025-06-22</span>&nbsp;·&nbsp;创建于:&nbsp;2021-07-01&nbsp;·&nbsp;25 min&nbsp;·&nbsp;5264 words</footer><a class=entry-link aria-label="post link to go tips(持续更新)" href=https://duck-dd.github.io/posts/2025-06-22-go-tips/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>golang singleflight</h2></header><div class=entry-content><p>高并发场景下，有时我们很多并发goroutine内有逻辑重合，可能拉了数据库同一张表的数据，可能拉了同一个远程图片，这些数据通常是偏静态的，那么没有必要在每个goroutine内部都做这个操作，可能会拉高上游服务的负载，可能会影响本地的执行效率，可能会浪费本地的网卡资源等。
通常我们会依赖缓存来解决这个问题，这也确实是行之有效的；但是golang并发场景也给了我们更简便的实现方法：golang.org/x/sync/singleflight。
如下面的例子，doSth有2s的Sleep模拟执行过程；我们分了两组for+routine，中间有1s的Sleep，确保第一个发起doSth的index是可控的，然后我们看到输出实际doSth只执行了一次，所有routine共享了同一份结果。 PS：所有的shared返回值都是true，可能并不是大脑第一印象的第一个实际执行者是false，其他人是true
package main import ( "fmt" "sync" "sync/atomic" "time" "golang.org/x/sync/singleflight" ) func doSth(index int) (any, error) { time.Sleep(2 * time.Second) return fmt.Sprintf("result_%d", index), nil } func main() { var g singleflight.Group var wg sync.WaitGroup var doCount int32 for i := 100; i &lt; 101; i++ { wg.Add(1) index := i go func() { defer wg.Done() ret, err, shared := g.Do("key", func() (interface{}, error) { atomic.AddInt32(&amp;doCount, 1) v,e := doSth(index) fmt.Printf("index:%d, v: %v, err: %v\n", index, v, e) return v,e }) fmt.Printf("index:%d, ret:%v, shared:%v, err:%v\n", index, ret, shared, err) }() } time.Sleep(time.Second) for i := 0; i &lt; 5; i++ { wg.Add(1) index := i go func() { defer wg.Done() ret, err, shared := g.Do("key", func() (interface{}, error) { atomic.AddInt32(&amp;doCount, 1) v,e := doSth(index) fmt.Printf("index:%d, v: %v, err: %v\n", index, v, e) return v,e }) fmt.Printf("index:%d, ret:%v, shared:%v, err:%v\n", index, ret, shared, err) }() } wg.Wait() fmt.Printf("实际执行次数: %d\n", doCount) } ------ output: index:100, v: result_100, err: &lt;nil> index:100, ret:result_100, shared:true, err:&lt;nil> index:0, ret:result_100, shared:true, err:&lt;nil> index:4, ret:result_100, shared:true, err:&lt;nil> index:2, ret:result_100, shared:true, err:&lt;nil> index:3, ret:result_100, shared:true, err:&lt;nil> index:1, ret:result_100, shared:true, err:&lt;nil> 实际执行次数: 1 真正发起共享的函数Do入参是有key的，我们把key做个替换，会发现不同key之间不共享，如下：
...</p></div><footer class=entry-footer><span title='2025-04-05 00:00:00 +0000 UTC'>2025-04-05</span>&nbsp;·&nbsp;创建于:&nbsp;2025-04-05&nbsp;·&nbsp;3 min&nbsp;·&nbsp;565 words</footer><a class=entry-link aria-label="post link to golang singleflight" href=https://duck-dd.github.io/posts/2025-04-05-golang-singleflight/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>golang select case机会均等</h2></header><div class=entry-content><p>验证 我们每天都在使用下面这样的用法，对于这种多条件分支判定，我们从来不会指定权重，按固有思维，多条件间应该是机会均等的，那么golang如何做的呢？
select { case &lt;-ch1: do sth case &lt;-ch2: do sth case &lt;-ch3: do sth } 我们先来看看到底是不是机会均等的。
package main import("fmt") func main() { sum1, sum2, sum3 := 0, 0, 0 for loop:=0; loop&lt;8 ; loop++ { count1, count2, count3 := 0, 0, 0 ch1, ch2, ch3 := make(chan int), make(chan int), make(chan int) go func(){for { ch1&lt;-1 }}() go func(){for { ch2&lt;-1 }}() go func(){for { ch3&lt;-1 }}() for i := 0; i &lt; 10000; i++ { select { case &lt;-ch1: count1++ sum1++ case &lt;-ch2: count2++ sum2++ case &lt;-ch3: count3++ sum3++ } } fmt.Println("loop ", loop+1, ": ", count1, count2, count3) } fmt.Println("sum: ", sum1, sum2, sum3) } 结果: loop 1 : 1535 5446 3019 loop 2 : 1607 5004 3389 loop 3 : 1146 3549 5305 loop 4 : 4100 2601 3299 loop 5 : 5938 2260 1802 loop 6 : 923 1268 7809 loop 7 : 4958 2273 2769 loop 8 : 3162 3432 3406 sum: 23369 25833 30798 诶，好像不太对啊，尤其loop 7，偏差到飞起了啊…总量的偏差也大的离谱…
...</p></div><footer class=entry-footer><span title='2022-04-13 00:00:00 +0000 UTC'>2022-04-13</span>&nbsp;·&nbsp;创建于:&nbsp;2022-04-13&nbsp;·&nbsp;4 min&nbsp;·&nbsp;712 words</footer><a class=entry-link aria-label="post link to golang select case机会均等" href=https://duck-dd.github.io/posts/2022-04-13-golang-select-case%E6%9C%BA%E4%BC%9A%E5%9D%87%E7%AD%89/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Golang schedule</h2></header><div class=entry-content><p>写在前面 runtime包实现了所有goroutine scheduler、memory allocator、garbage collector细节，理论上可以从runtime包获取一切信息，没有直接怼源码，而是站在巨人的肩膀上（直接吃大佬们吃剩下的）。
搜集到的材料，大家都是基于不同的go版本做的分析，而go版本迭代调度算法也在持续更新，所以整理的可能有些乱。但是可以保证的是，所有材料都是GM->GMP演化后的材料。
GM go1.1版本以前，调度使用GM模型，如下图所示。简单的理解GM模型，就是有一个始终执行的调度函数schedule不停的执行调度计算，当某个M的G执行完成了，调度器就把这个M放回M队列，可绑定执行其他G（如果某个M+G发生了syscall，那么本来并发度是通过M数量控制的，此时并发度就降低了？）；如果G执行过程中创建新的G，会将新的G放入到G全局可执行队列中。G全局可执行队列的操作有一把全局锁，这导致了各个M对G全局队列的操作存在严重的竞争。
下面这段完全是我的臆测，请别太相信：
简单概括呢，所以可以认为有：
G全局可执行队列(以下也可能简称G可执行队列) M可用队列 调度器要做的事就是：
从G的可执行队列取G并从M的可用队列取M，将二者绑定开始执行G 对于已经执行完的G，销毁G并立即将M释放回M可用队列供后续使用 那么GM模型有哪些问题呢？
(重点问题)单一的全局mutex(sched.lock)和集中状态管理 mutex需要保护所有与全局goroutine队列相关操作(创建、完成、重排等等)，竞争严重 (重点问题)per-M内存(M.mcache)问题 每个M都需要一个mcache，会导致资源消耗过大(每个mcache可以吸纳到2MB的内存缓存和其他缓存) 举个栗子，一个陷入syscall的M并不需要使用cache，但是在全部的M中，陷入系统调用的M与执行goroutine的M的比例可能是N:1(N>>1)，这就导致了N/(N+1)比例的mcache在闲置 数据局部性差: 举个栗子，M1执行G1，此时创建了G2，G2通常是立刻进入了G全局可执行队列，而此时M1还在执行G1，所以G2通常被其他M执行，但是G1和G2通常强相关，所以G2最好也在M1上执行，因为G2对M1的缓存命中率更高 goroutine传递问题 goroutine(G)交接(G.nextg)，M之间会经常交接可运行的G 再通俗点说，就是G空转，本来能够好好在一个M上执行完，但是由于全局队列的存在，G一旦回全局队列了，下次就不知道被哪个M取走了，所以叫“空转”；M加载G的上下文是有开销的，所以空转会导致性能下降 频繁的线程阻塞/解阻塞 syscalls情况下，线程经常被阻塞和解阻塞，增加了很多额外开销 通俗点说，M+G syscall，M阻塞，syscall完成后，M解阻塞继续执行G（如果是通过M数量控制并发度，这是不是就导致了并发度降低？） GMP 基于以上说的GM的问题，go1.1以后开始使用GMP调度模型。 G、M、P的定义如下(***/src/runtime/runtime2.go)。
type g struct { // Stack parameters. // stack describes the actual stack memory: [stack.lo, stack.hi). // stackguard0 is the stack pointer compared in the Go stack growth prologue. // It is stack.lo+StackGuard normally, but can be StackPreempt to trigger a preemption. // stackguard1 is the stack pointer compared in the C stack growth prologue. // It is stack.lo+StackGuard on g0 and gsignal stacks. // It is ~0 on other goroutine stacks, to trigger a call to morestackc (and crash). stack stack // offset known to runtime/cgo stackguard0 uintptr // offset known to liblink stackguard1 uintptr // offset known to liblink _panic *_panic // innermost panic - offset known to liblink _defer *_defer // innermost defer m *m // current m; offset known to arm liblink sched gobuf syscallsp uintptr // if status==Gsyscall, syscallsp = sched.sp to use during gc syscallpc uintptr // if status==Gsyscall, syscallpc = sched.pc to use during gc stktopsp uintptr // expected sp at top of stack, to check in traceback param unsafe.Pointer // passed parameter on wakeup atomicstatus uint32 stackLock uint32 // sigprof/scang lock; TODO: fold in to atomicstatus goid int64 schedlink guintptr waitsince int64 // approx time when the g become blocked waitreason waitReason // if status==Gwaiting preempt bool // preemption signal, duplicates stackguard0 = stackpreempt preemptStop bool // transition to _Gpreempted on preemption; otherwise, just deschedule preemptShrink bool // shrink stack at synchronous safe point // asyncSafePoint is set if g is stopped at an asynchronous // safe point. This means there are frames on the stack // without precise pointer information. asyncSafePoint bool paniconfault bool // panic (instead of crash) on unexpected fault address gcscandone bool // g has scanned stack; protected by _Gscan bit in status throwsplit bool // must not split stack // activeStackChans indicates that there are unlocked channels // pointing into this goroutine's stack. If true, stack // copying needs to acquire channel locks to protect these // areas of the stack. activeStackChans bool // parkingOnChan indicates that the goroutine is about to // park on a chansend or chanrecv. Used to signal an unsafe point // for stack shrinking. It's a boolean value, but is updated atomically. parkingOnChan uint8 raceignore int8 // ignore race detection events sysblocktraced bool // StartTrace has emitted EvGoInSyscall about this goroutine sysexitticks int64 // cputicks when syscall has returned (for tracing) traceseq uint64 // trace event sequencer tracelastp puintptr // last P emitted an event for this goroutine lockedm muintptr sig uint32 writebuf []byte sigcode0 uintptr sigcode1 uintptr sigpc uintptr gopc uintptr // pc of go statement that created this goroutine ancestors *[]ancestorInfo // ancestor information goroutine(s) that created this goroutine (only used if debug.tracebackancestors) startpc uintptr // pc of goroutine function racectx uintptr waiting *sudog // sudog structures this g is waiting on (that have a valid elem ptr); in lock order cgoCtxt []uintptr // cgo traceback context labels unsafe.Pointer // profiler labels timer *timer // cached timer for time.Sleep selectDone uint32 // are we participating in a select and did someone win the race? // Per-G GC state // gcAssistBytes is this G's GC assist credit in terms of // bytes allocated. If this is positive, then the G has credit // to allocate gcAssistBytes bytes without assisting. If this // is negative, then the G must correct this by performing // scan work. We track this in bytes to make it fast to update // and check for debt in the malloc hot path. The assist ratio // determines how this corresponds to scan work debt. gcAssistBytes int64 } type m struct { g0 *g // goroutine with scheduling stack morebuf gobuf // gobuf arg to morestack divmod uint32 // div/mod denominator for arm - known to liblink // Fields not known to debuggers. procid uint64 // for debuggers, but offset not hard-coded gsignal *g // signal-handling g goSigStack gsignalStack // Go-allocated signal handling stack sigmask sigset // storage for saved signal mask tls [6]uintptr // thread-local storage (for x86 extern register) mstartfn func() curg *g // current running goroutine caughtsig guintptr // goroutine running during fatal signal p puintptr // attached p for executing go code (nil if not executing go code) nextp puintptr oldp puintptr // the p that was attached before executing a syscall id int64 mallocing int32 throwing int32 preemptoff string // if != "", keep curg running on this m locks int32 dying int32 profilehz int32 spinning bool // m is out of work and is actively looking for work blocked bool // m is blocked on a note newSigstack bool // minit on C thread called sigaltstack printlock int8 incgo bool // m is executing a cgo call freeWait uint32 // if == 0, safe to free g0 and delete m (atomic) fastrand [2]uint32 needextram bool traceback uint8 ncgocall uint64 // number of cgo calls in total ncgo int32 // number of cgo calls currently in progress cgoCallersUse uint32 // if non-zero, cgoCallers in use temporarily cgoCallers *cgoCallers // cgo traceback if crashing in cgo call park note alllink *m // on allm schedlink muintptr lockedg guintptr createstack [32]uintptr // stack that created this thread. lockedExt uint32 // tracking for external LockOSThread lockedInt uint32 // tracking for internal lockOSThread nextwaitm muintptr // next m waiting for lock waitunlockf func(*g, unsafe.Pointer) bool waitlock unsafe.Pointer waittraceev byte waittraceskip int startingtrace bool syscalltick uint32 freelink *m // on sched.freem // these are here because they are too large to be on the stack // of low-level NOSPLIT functions. libcall libcall libcallpc uintptr // for cpu profiler libcallsp uintptr libcallg guintptr syscall libcall // stores syscall parameters on windows vdsoSP uintptr // SP for traceback while in VDSO call (0 if not in call) vdsoPC uintptr // PC for traceback while in VDSO call // preemptGen counts the number of completed preemption // signals. This is used to detect when a preemption is // requested, but fails. Accessed atomically. preemptGen uint32 // Whether this is a pending preemption signal on this M. // Accessed atomically. signalPending uint32 dlogPerM mOS // Up to 10 locks held by this m, maintained by the lock ranking code. locksHeldLen int locksHeld [10]heldLockInfo } type p struct { id int32 status uint32 // one of pidle/prunning/... link puintptr schedtick uint32 // incremented on every scheduler call syscalltick uint32 // incremented on every system call sysmontick sysmontick // last tick observed by sysmon m muintptr // back-link to associated m (nil if idle) mcache *mcache pcache pageCache raceprocctx uintptr deferpool [5][]*_defer // pool of available defer structs of different sizes (see panic.go) deferpoolbuf [5][32]*_defer // Cache of goroutine ids, amortizes accesses to runtime·sched.goidgen. goidcache uint64 goidcacheend uint64 // Queue of runnable goroutines. Accessed without lock. runqhead uint32 runqtail uint32 runq [256]guintptr // runnext, if non-nil, is a runnable G that was ready'd by // the current G and should be run next instead of what's in // runq if there's time remaining in the running G's time // slice. It will inherit the time left in the current time // slice. If a set of goroutines is locked in a // communicate-and-wait pattern, this schedules that set as a // unit and eliminates the (potentially large) scheduling // latency that otherwise arises from adding the ready'd // goroutines to the end of the run queue. runnext guintptr // Available G's (status == Gdead) gFree struct { gList n int32 } sudogcache []*sudog sudogbuf [128]*sudog // Cache of mspan objects from the heap. mspancache struct { // We need an explicit length here because this field is used // in allocation codepaths where write barriers are not allowed, // and eliminating the write barrier/keeping it eliminated from // slice updates is tricky, moreso than just managing the length // ourselves. len int buf [128]*mspan } tracebuf traceBufPtr // traceSweep indicates the sweep events should be traced. // This is used to defer the sweep start event until a span // has actually been swept. traceSweep bool // traceSwept and traceReclaimed track the number of bytes // swept and reclaimed by sweeping in the current sweep loop. traceSwept, traceReclaimed uintptr palloc persistentAlloc // per-P to avoid mutex _ uint32 // Alignment for atomic fields below // The when field of the first entry on the timer heap. // This is updated using atomic functions. // This is 0 if the timer heap is empty. timer0When uint64 // Per-P GC state gcAssistTime int64 // Nanoseconds in assistAlloc gcFractionalMarkTime int64 // Nanoseconds in fractional mark worker (atomic) gcBgMarkWorker guintptr // (atomic) gcMarkWorkerMode gcMarkWorkerMode // gcMarkWorkerStartTime is the nanotime() at which this mark // worker started. gcMarkWorkerStartTime int64 // gcw is this P's GC work buffer cache. The work buffer is // filled by write barriers, drained by mutator assists, and // disposed on certain GC state transitions. gcw gcWork // wbBuf is this P's GC write barrier buffer. // // TODO: Consider caching this in the running G. wbBuf wbBuf runSafePointFn uint32 // if 1, run sched.safePointFn at next safe point // Lock for timers. We normally access the timers while running // on this P, but the scheduler can also do it from a different P. timersLock mutex // Actions to take at some time. This is used to implement the // standard library's time package. // Must hold timersLock to access. timers []*timer // Number of timers in P's heap. // Modified using atomic instructions. numTimers uint32 // Number of timerModifiedEarlier timers on P's heap. // This should only be modified while holding timersLock, // or while the timer status is in a transient state // such as timerModifying. adjustTimers uint32 // Number of timerDeleted timers in P's heap. // Modified using atomic instructions. deletedTimers uint32 // Race context used while executing timer functions. timerRaceCtx uintptr // preempt is set to indicate that this P should be enter the // scheduler ASAP (regardless of what G is running on it). preempt bool pad cpu.CacheLinePad } GMP模型的一些概念 上面M中有两个g需要关注下，curg和g0。 curg就是M当前绑定的G。 g0是带有调度栈的goroutine，普通的G的栈是分配在堆上的可增长的栈，而g0的栈是M对应的线程的栈。所有调度相关的代码，会先切换到该goroutine的栈中执行。即，线程的栈也是用的g实现，而不是使用的OS。
...</p></div><footer class=entry-footer><span title='2021-08-21 00:00:00 +0000 UTC'>2021-08-21</span>&nbsp;·&nbsp;创建于:&nbsp;2021-08-21&nbsp;·&nbsp;9 min&nbsp;·&nbsp;1904 words</footer><a class=entry-link aria-label="post link to Golang schedule" href=https://duck-dd.github.io/posts/2021-08-21-go-schedule/></a></article></main><footer class=footer><span>&copy; 2025 <a href=https://duck-dd.github.io/>Duck</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>